#1st  std and mean

import numpy as np
import pandas as pd
import seaborn as sns

def generate_scores(mean=60,std_dev=12,num_samples=200):
    np.random.seed(27)
    scores = np.random.normal(loc=mean,scale=std_dev,size=num_samples)
    scores = np.round(scores, decimals=0)
    return scores
scores_data = generate_scores()

sns.set_theme()
sns.displot(data=scores_data).set(title="Distribution of Scores",
xlabel="Scores")

df_scores = pd.DataFrame(scores_data,columns=['score'])
lower_limit = df_scores.mean() - 3*df_scores.std()
upper_limit = df_scores.mean() + 3*df_scores.std()
print(lower_limit)
print(upper_limit)

df_scores_filtered=df_scores[(df_scores[['score']]>lower_limit)&(df_scores[['score']]<upper_limit)]
print(df_scores_filtered)







#3rd k-means

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]
data = list(zip(x, y))
print(data)
inertias = []

for i in range(1,11):
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(data)
    inertias.append(kmeans.inertia_)

plt.plot(range(1,11), inertias, marker='o')
plt.title('Elbow method')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.show()

kmeans = KMeans(n_clusters=2)
kmeans.fit(data)
plt.scatter(x, y, c=kmeans.labels_)
plt.show()







#4th Agglomerative Algorithm for Clustering
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt

X = [[1, 2], [1, 4], [1, 0],
[4, 2], [4, 4], [4, 0]]

Z = linkage(X, 'ward')
dendrogram(Z)
plt.show()




#5th EDA process
import pandas as pd
import numpy as np
import seaborn as sns
#Load the data
df = pd.read_csv('titanic.csv')
#View the data
df.head()
df.info()
df.describe()












2nd - Decision Tree

#!/usr/bin/env python
# coding: utf-8



from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
import pandas as pd
import numpy as np




from sklearn.datasets import load_iris





iris = load_iris()
iris
iris.data




iris.target




import seaborn as sns
df = sns.load_dataset("iris")



df.head(3)


# In[17]:


X = df.iloc[:,:-1]
y = iris.target


X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 40)

clf_entropy = DecisionTreeClassifier(criterion="entropy",random_state=100,max_depth=3)

clf_entropy.fit(X_train, y_train)

y_pred = clf_entropy.predict(X_test)

y_pred

print(accuracy_score(y_test,y_pred)*100)





